{"id":"9f2e9f59-22ea-413b-8732-ced3cba393d3","object":"chat.completion","created":1741195164,"model":"grok-2-1212","choices":[{"index":0,"message":{"role":"assistant","content":"# Streaming OpenAI Responses and Processing Full Completion\n\nWhen dealing with streaming responses from OpenAI, you can indeed stream the response to the user in real-time while also processing the full completion once it's ready. Here's how you can achieve this:\n\n## Streaming to the User\n\nTo stream the response to the user, you'll need to set up your server to handle streaming data. Here's an example using Express to stream the response:\n\n```javascript\nconst express = require('express');\nconst { Configuration, OpenAIApi } = require(\"openai\");\n\nconst app = express();\nconst configuration = new Configuration({\n  apiKey: process.env.OPENAI_API_KEY,\n});\nconst openai = new OpenAIApi(configuration);\n\napp.get('/stream', async (req, res) => {\n  res.setHeader('Content-Type', 'text/event-stream');\n  res.setHeader('Cache-Control', 'no-cache');\n  res.setHeader('Connection', 'keep-alive');\n\n  const completion = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt: \"Your prompt here\",\n    max_tokens: 100,\n    stream: true,\n  });\n\n  completion.data.on('data', data => {\n    const lines = data.toString().split('\\n').filter(line => line.trim());\n    for (const line of lines) {\n      const message = line.replace(/^data: /, '');\n      if (message === '[DONE]') {\n        res.write('event: end\\ndata: {}\\n\\n');\n      } else {\n        const parsed = JSON.parse(message);\n        res.write(`data: ${JSON.stringify(parsed.choices[0].text)}\\n\\n`);\n      }\n    }\n  });\n\n  completion.data.on('end', () => {\n    res.end();\n  });\n});\n\napp.listen(3000, () => console.log('Server running on port 3000'));\n```\n\nIn this example, the server streams the response to the client using Server-Sent Events (SSE). The client can then display this data in real-time.\n\n## Storing and Processing the Full Response\n\nTo process the full response once it's ready, you will need to store the stream as you show it to the user. Here's how you can modify the above code to store and process the full response:\n\n```javascript\nconst express = require('express');\nconst { Configuration, OpenAIApi } = require(\"openai\");\n\nconst app = express();\nconst configuration = new Configuration({\n  apiKey: process.env.OPENAI_API_KEY,\n});\nconst openai = new OpenAIApi(configuration);\n\napp.get('/stream', async (req, res) => {\n  res.setHeader('Content-Type', 'text/event-stream');\n  res.setHeader('Cache-Control', 'no-cache');\n  res.setHeader('Connection', 'keep-alive');\n\n  let fullResponse = ''; // Variable to store the full response\n\n  const completion = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt: \"Your prompt here\",\n    max_tokens: 100,\n    stream: true,\n  });\n\n  completion.data.on('data', data => {\n    const lines = data.toString().split('\\n').filter(line => line.trim());\n    for (const line of lines) {\n      const message = line.replace(/^data: /, '');\n      if (message === '[DONE]') {\n        res.write('event: end\\ndata: {}\\n\\n');\n        // Process the full response here\n        processFullResponse(fullResponse);\n      } else {\n        const parsed = JSON.parse(message);\n        const text = parsed.choices[0].text;\n        fullResponse += text; // Append to the full response\n        res.write(`data: ${JSON.stringify(text)}\\n\\n`); // Stream to the user\n      }\n    }\n  });\n\n  completion.data.on('end', () => {\n    res.end();\n  });\n});\n\nfunction processFullResponse(fullResponse) {\n  // Example: Log the full response\n  console.log('Full Response:', fullResponse);\n  // Add your processing logic here\n}\n\napp.listen(3000, () => console.log('Server running on port 3000'));\n```\n\nIn this modified example, we store the full response in the `fullResponse` variable as we stream it to the user. Once the response is complete (`[DONE]` is received), we call the `processFullResponse` function to handle the full response.\n\n## Conclusion\n\nBy storing the stream as you show it to the user, you can achieve both real-time streaming and processing of the full response once it's ready. This approach allows you to provide an interactive experience for the user while also performing any necessary operations on the complete data.\n\n@EOF@\n[OpenAI, streaming, response, real-time, processing, full completion, Server-Sent Events, SSE, Express, Node.js]","refusal":null},"finish_reason":"stop"}],"usage":{"prompt_tokens":869,"completion_tokens":1013,"reasoning_tokens":0,"total_tokens":1882,"prompt_tokens_details":{"text_tokens":869,"audio_tokens":0,"image_tokens":0,"cached_tokens":0}},"system_fingerprint":"fp_5c0c5bd9d9"}