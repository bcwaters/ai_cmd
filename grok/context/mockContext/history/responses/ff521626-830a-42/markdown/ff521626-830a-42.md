# Decision Tree Regressor for Home Value Prediction

In this example, we'll use ASCII art to visualize a Decision Tree Regressor for predicting home values based on three features: lot size, number of bedrooms, and year built.

```
          [Home Value Prediction]
               /         |         \
              /          |          \
             /           |           \
    [Lot Size]    [Bedrooms]    [Year Built]
       <= 5000         <= 3         <= 1990
         / \             / \             / \
        /   \           /   \           /   \
       /     \         /     \         /     \
  [Small Lot]  [Large Lot] [Few Beds] [Many Beds] [Older] [Newer]
    Value: $200k    Value: $350k   Value: $250k   Value: $400k  Value: $220k  Value: $380k
```

### Explanation:

1. **Root Node (Home Value Prediction)**: This is where the decision tree starts. The tree splits based on the most significant feature.

2. **First Level Splits**:
   - **Lot Size**: If the lot size is less than or equal to 5000 square feet, the house falls into the "Small Lot" category, otherwise "Large Lot".
   - **Bedrooms**: If the number of bedrooms is less than or equal to 3, the house is categorized as "Few Beds", otherwise "Many Beds".
   - **Year Built**: If the house was built on or before 1990, it's "Older", otherwise "Newer".

3. **Leaf Nodes**: These are the final predictions. Each leaf node represents a predicted home value based on the path taken through the tree.

This simple tree demonstrates how a Decision Tree Regressor can be used to predict home values by sequentially splitting the dataset on different features until reaching a decision.

